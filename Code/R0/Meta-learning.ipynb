{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8947f26d6a746f5d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for r in range(2):\n",
    "    time_start = time.time()\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    print(f\"START: {sub_lst}, {r+1}th subject\")\n",
    "\n",
    "    X_tr, Y_tr, X_te, Y_te = step1(sub_lst, train_init_rep, test_rep, Feature_idx)\n",
    "\n",
    "    _, _, for_proto_X, for_proto_y = get_data(X_tr, Y_tr, X_te, Y_te, K_shot, split=True)\n",
    "\n",
    "\n",
    "    input_shape = X_tr.shape[1:]\n",
    "\n",
    "    model = build_model(num_classes, input_shape)\n",
    "    model.compile(loss=lambda y_true, y_pred: custom_loss(y_true, y_pred, alpha), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "    train_embeddings = model.predict(for_proto_X, verbose=0)\n",
    "    train_labels = np.argmax(for_proto_y, axis=1)\n",
    "    prototypes = calculate_prototypes(train_embeddings, train_labels, num_classes)\n",
    "\n",
    "    for meta_iter in range(meta_iters):\n",
    "        frac_done = meta_iter / meta_iters\n",
    "        cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "        old_vars = model.get_weights()\n",
    "\n",
    "        #train_dataset = get_data(X_tr, Y_tr, X_te, Y_te, K_shot, split=False)\n",
    "        train_dataset, test_data, for_proto_X, for_proto_y = get_data(X_tr, Y_tr, X_te, Y_te, K_shot, split=True)\n",
    "\n",
    "        # Inner loop - episode\n",
    "        #model.fit(mini_dataset, epochs=30, verbose=0)  # Train on the mini-batch\n",
    "        result = model.fit(train_dataset, epochs=100, validation_data=test_data, callbacks=[MemoryCallback()], verbose=0)  # Outer loop training\n",
    "        val_acc = np.max(result.history['val_accuracy'])\n",
    "        accuracies.append(val_acc)\n",
    "        print(f'Subject {r+1}  -  Iter {meta_iter}/{meta_iters} - {val_acc},  max so far: {np.max(accuracies)}')\n",
    "\n",
    "\n",
    "        # Apply meta-update using the new model weights\n",
    "        # 여기서 예전 가중치들이랑 최근꺼랑 업데이트\n",
    "        new_vars = model.get_weights()\n",
    "        for var in range(len(new_vars)):  # SGD for meta gradient\n",
    "            new_vars[var] = old_vars[var] + ((new_vars[var] - old_vars[var]) * cur_meta_step_size)\n",
    "\n",
    "\n",
    "        # meta 업데이트를 한 가중치들을 모델에다가 넣음\n",
    "        model.set_weights(new_vars)  # After the meta-learning step, reload the newly-trained weights into the model.\n",
    "    time_end = time.time()\n",
    "    print(f\"Total training time: {time_end - time_start:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
